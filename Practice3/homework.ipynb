{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Домашнее задание №3: Деревья решений и ансамбли\n",
    "\n",
    "## Цель\n",
    "\n",
    "Закрепить на практике темы:\n",
    "\n",
    "- логистическая регрессия как базовая модель для классификации;\n",
    "- дерево решений как нелинейная модель;\n",
    "- случайный лес как бэггинг деревьев;\n",
    "- градиентный бустинг по деревьям.\n",
    "\n",
    "Сравнить модели по качеству и переобучению на **одном реальном датасете**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Данные\n",
    "\n",
    "**Датасет:** используйте `load_breast_cancer` из `sklearn.datasets` (бинарная классификация).\n",
    "\n",
    "1.1. Загрузите данные:\n",
    "\n",
    "- выведите размерность матрицы признаков (`n_samples`, `n_features`);\n",
    "- выведите уникальные значения целевого класса и их количество.\n",
    "\n",
    "Посчитайте:\n",
    "- сколько объектов и признаков;\n",
    "- какие классы есть и что они означают.\n",
    "\n",
    "1.2. Разбиение на выборки:\n",
    "\n",
    "- используйте `train_test_split` с `test_size` в диапазоне 0.2–0.3;\n",
    "- зафиксируйте `random_state`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Базовый уровень: логистическая регрессия\n",
    "\n",
    "2.1. Обучите `LogisticRegression` на обучающей выборке.\n",
    "\n",
    "- опционально используйте масштабирование признаков (`StandardScaler + Pipeline`).\n",
    "\n",
    "2.2. Посчитайте метрики классификации на обучающей и тестовой выборках\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Дерево решений (DecisionTreeClassifier)\n",
    "\n",
    "3.1. Обучите `DecisionTreeClassifier` с настройками по умолчанию.\n",
    "\n",
    "- Посчитайте метрики классификации на обучающей и тестовой выборках\n",
    "\n",
    "3.2. Исследование глубины дерева:\n",
    "\n",
    "- обучите несколько моделей с разными `max_depth`, например:  \n",
    "  `[1, 2, 3, 4, 5, 10, None]`;\n",
    "- для каждого значения посчитайте train/test метрики;\n",
    "- постройте график:\n",
    "  - по оси X — `max_depth` (можно заменить `None` на какое-то число в подписи);\n",
    "  - по оси Y — accuracy (две кривые: `train` и `test`).\n",
    "\n",
    "Разберитесь:\n",
    "\n",
    "- при каких глубинах наблюдается недообучение;\n",
    "- при каких — явное переобучение.\n",
    "\n",
    "3.3. Интерпретация неглубокого дерева:\n",
    "\n",
    "- выберите разумное значение `max_depth` (например, 3 или 4);\n",
    "- обучите дерево с этим ограничением;\n",
    "- визуализируйте его с помощью `plot_tree` **или** выведите правила через `export_text`;\n",
    "- разберитесь, какие признаки и пороги используются ближе к корню и как это можно интерпретировать.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Случайный лес (RandomForestClassifier)\n",
    "\n",
    "4.1. Обучите `RandomForestClassifier` с базовыми настройками, например:\n",
    "\n",
    "- `n_estimators = 200`,\n",
    "- `random_state` зафиксировать,\n",
    "- остальные параметры можно оставить по умолчанию.\n",
    "\n",
    "Посчитайте метрики на train/test и кратко сравните с одиночным деревом и логистической регрессией.\n",
    "\n",
    "4.2. Влияние числа деревьев:\n",
    "\n",
    "- обучите леса с разными `n_estimators`, например:  \n",
    "  `[10, 50, 100, 200, 500]`;\n",
    "- для каждого значения посчитайте train/test метрики;\n",
    "- постройте график:\n",
    "  - X — `n_estimators`,\n",
    "  - Y — accuracy (train и test).\n",
    "\n",
    "Разберитесь:\n",
    "\n",
    "- как меняется качество на тесте при росте числа деревьев;\n",
    "- стабилизируется ли качество, растёт ли переобучение.\n",
    "\n",
    "4.3. Важность признаков:\n",
    "\n",
    "- для одного обученного леса получите `feature_importances_`;\n",
    "- выберите несколько (например, 5–10) наиболее важных признаков и постройте для них bar chart;\n",
    "- кратко прокомментируйте: логично ли, что именно эти признаки наиболее важны (опираясь на описание датасета).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Градиентный бустинг (GradientBoostingClassifier)\n",
    "\n",
    "5.1. Базовая модель бустинга:\n",
    "\n",
    "- обучите `GradientBoostingClassifier` с настройками, например:  \n",
    "  `n_estimators=200`, `learning_rate=0.1`, `max_depth=3`, `random_state` зафиксировать;\n",
    "- посчитайте train/test метрики;\n",
    "- сравните с логистической регрессией, деревом и лесом.\n",
    "\n",
    "5.2. Влияние числа деревьев при фиксированном `learning_rate`:\n",
    "\n",
    "- выберите один `learning_rate` (например, `0.1`);\n",
    "- обучите модели с разными `n_estimators`, например:  \n",
    "  `[20, 50, 100, 200, 400]`;\n",
    "- для каждого значения посчитайте train/test метрики;\n",
    "- постройте график:\n",
    "  - X — `n_estimators`,\n",
    "  - Y — accuracy (train и test).\n",
    "\n",
    "Разберитесь:\n",
    "\n",
    "- поясните, при каком диапазоне `n_estimators` модель даёт лучшее качество на тесте;\n",
    "- есть ли признаки переобучения при увеличении числа деревьев.\n",
    "\n",
    "(Если удобно, можно для одной конфигурации использовать `staged_predict`, чтобы не обучать модель много раз)\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Итоговое сравнение\n",
    "\n",
    "Соберите в одну таблицу результаты для основных моделей:\n",
    "\n",
    "- логистическая регрессия (одна конфигурация),\n",
    "- дерево решений (выбранная «разумная» глубина),\n",
    "- случайный лес (одна выбранная конфигурация),\n",
    "- градиентный бустинг (одна выбранная конфигурация).\n",
    "\n",
    "Для каждой модели укажите:\n",
    "\n",
    "- краткое имя / тип модели;\n",
    "- основные ключевые гиперпараметры (например, `max_depth`, `n_estimators`, `learning_rate`);\n",
    "- train и test метрики."
   ],
   "id": "9c9c238d7ef63d28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1f8beec18d6cffea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
